{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc1dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.api import qqplot\n",
    "from tensorflow import keras\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import SimpleRNN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "dataset = pandas.read_csv(r'D:\\專題\\各縣市每日確診資料\\台北市每日確診數.csv', usecols=[2], engine='python', skipfooter=3,encoding='utf-8')\n",
    "plt.plot(dataset)\n",
    "plt.savefig('Taipei.png')\n",
    "plt.show()\n",
    "\n",
    "# 畫出 ACF 12 期的效應\n",
    "sm.graphics.tsa.plot_acf(dataset, lags=24)\n",
    "plt.savefig('Taipei_acf_24.png')\n",
    "plt.show()\n",
    "# 畫出 PACF 12 期的效應\n",
    "sm.graphics.tsa.plot_pacf(dataset, lags=24)\n",
    "plt.savefig('Taipei_pacf_24.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f76cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 產生 (X, Y) 資料集, Y 是下一期的感染人數\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "# 載入訓練資料\n",
    "dataframe = read_csv(r'D:\\專題\\各縣市每日確診資料\\台北市每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "dataframe=dataframe.drop(dataframe[dataframe['確定病例數']==0].index,axis=0)\n",
    "print(dataframe)\n",
    "#plt.plot(dataframe)\n",
    "\n",
    "dataset = dataframe.values\n",
    "print(len(dataset))\n",
    "#dataset=np.delete(dataset,[0,768],axis=0)\n",
    "\n",
    "# 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1a08e9",
   "metadata": {},
   "source": [
    "## LSTM架構"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6674506b",
   "metadata": {},
   "source": [
    "### Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e188543",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(7)\n",
    "\n",
    "# 2/3 資料為訓練資料， 1/3 資料為測試資料\n",
    "train_size = int(len(dataset) * 0.9)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "# 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "# 建立及訓練 GRU 模型\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(1, look_back)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
    "#opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "sgd = optimizers.SGD(learning_rate=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd ,metrics=['mse'])\n",
    "\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"taipei_gru_lstm.keras\",\n",
    "    save_weights_only=True,\n",
    "    monitor='val_mse',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(trainX, trainY,validation_data=(testX, testY), epochs=10000, batch_size=10, verbose=1,callbacks=[model_checkpoint_callback])\n",
    "model.save('taipei.h5')\n",
    "# 預測\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "trainPredict=trainPredict.reshape(-1, 1)\n",
    "testPredict=testPredict.reshape(-1, 1)\n",
    "\n",
    "# 回復預測資料值為原始數據的規模\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "# calculate 均方根誤差(root mean squared error)\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "#model = keras.models.load_model(\"jena_lstm.keras\")\n",
    "#print(f\"Test MAE: {model.evaluate(testPredict)[1]:.2f}\")\n",
    "\n",
    "# 畫訓練資料趨勢圖\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "# 畫測試資料趨勢圖\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "\n",
    "\n",
    "# 畫原始資料趨勢圖8\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.savefig('Taipei_plot.png') \n",
    "plt.show()\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(dataset)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "days=len(testPredictPlot)\n",
    "plt.plot(scaler.inverse_transform(dataset[days-30:,:]))\n",
    "plt.plot(testPredictPlot[days-30:,:])\n",
    "plt.savefig(\"taipei_predict&real.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a8ec24",
   "metadata": {},
   "source": [
    "### Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6f4aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(7)\n",
    "\n",
    "# 2/3 資料為訓練資料， 1/3 資料為測試資料\n",
    "train_size = int(len(dataset) * 0.9)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "# 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "# 建立及訓練 GRU 模型\n",
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(1, look_back)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
    "#opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "sgd = optimizers.SGD(learning_rate=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd ,metrics=['mse'])\n",
    "\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"taipei_gru_lstm.keras\",\n",
    "    save_weights_only=True,\n",
    "    monitor='val_mse',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(trainX, trainY,validation_data=(testX, testY), epochs=10000, batch_size=10, verbose=1,callbacks=[model_checkpoint_callback])\n",
    "model.save('taipei.h5')\n",
    "# 預測\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "trainPredict=trainPredict.reshape(-1, 1)\n",
    "testPredict=testPredict.reshape(-1, 1)\n",
    "\n",
    "# 回復預測資料值為原始數據的規模\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "# calculate 均方根誤差(root mean squared error)\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "#model = keras.models.load_model(\"jena_lstm.keras\")\n",
    "#print(f\"Test MAE: {model.evaluate(testPredict)[1]:.2f}\")\n",
    "\n",
    "# 畫訓練資料趨勢圖\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "# 畫測試資料趨勢圖\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "\n",
    "\n",
    "# 畫原始資料趨勢圖8\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.savefig('Taipei_plot.png') \n",
    "plt.show()\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(dataset)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "days=len(testPredictPlot)\n",
    "plt.plot(scaler.inverse_transform(dataset[days-30:,:]))\n",
    "plt.plot(testPredictPlot[days-30:,:])\n",
    "plt.savefig(\"taipei_predict&real.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8772212c",
   "metadata": {},
   "source": [
    "### Model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186652fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(7)\n",
    "\n",
    "# 2/3 資料為訓練資料， 1/3 資料為測試資料\n",
    "train_size = int(len(dataset) * 0.9)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "# 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "# 建立及訓練 GRU 模型\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(1, look_back)),\n",
    "    LSTM(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
    "#opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "sgd = optimizers.SGD(learning_rate=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd ,metrics=['mse'])\n",
    "\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"taipei_gru_lstm.keras\",\n",
    "    save_weights_only=True,\n",
    "    monitor='val_mse',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(trainX, trainY,validation_data=(testX, testY), epochs=10000, batch_size=10, verbose=1,callbacks=[model_checkpoint_callback])\n",
    "model.save('taipei.h5')\n",
    "# 預測\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "# 回復預測資料值為原始數據的規模\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "# calculate 均方根誤差(root mean squared error)\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "#model = keras.models.load_model(\"jena_lstm.keras\")\n",
    "#print(f\"Test MAE: {model.evaluate(testPredict)[1]:.2f}\")\n",
    "\n",
    "# 畫訓練資料趨勢圖\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "# 畫測試資料趨勢圖\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "\n",
    "\n",
    "# 畫原始資料趨勢圖8\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.savefig('Taipei_plot.png') \n",
    "plt.show()\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(dataset)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "days=len(testPredictPlot)\n",
    "plt.plot(scaler.inverse_transform(dataset[days-30:,:]))\n",
    "plt.plot(testPredictPlot[days-30:,:])\n",
    "plt.savefig(\"taipei_predict&real.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf765d3f",
   "metadata": {},
   "source": [
    "### Modle4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee87d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(7)\n",
    "\n",
    "# 2/3 資料為訓練資料， 1/3 資料為測試資料\n",
    "train_size = int(len(dataset) * 0.9)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "# 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "# 建立及訓練 GRU 模型\n",
    "model = Sequential([\n",
    "    SimpleRNN(64, return_sequences=True, input_shape=(1, look_back)),\n",
    "    Dense(4, activation='relu'),\n",
    "    SimpleRNN(64, activation='sigmoid'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
    "#opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "sgd = optimizers.SGD(learning_rate=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd ,metrics=['mse'])\n",
    "\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"taipei_gru_lstm.keras\",\n",
    "    save_weights_only=True,\n",
    "    monitor='val_mse',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(trainX, trainY,validation_data=(testX, testY), epochs=10000, batch_size=10, verbose=1,callbacks=[model_checkpoint_callback])\n",
    "model.save('taipei.h5')\n",
    "# 預測\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "# 回復預測資料值為原始數據的規模\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "# calculate 均方根誤差(root mean squared error)\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "#model = keras.models.load_model(\"jena_lstm.keras\")\n",
    "#print(f\"Test MAE: {model.evaluate(testPredict)[1]:.2f}\")\n",
    "\n",
    "# 畫訓練資料趨勢圖\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "# 畫測試資料趨勢圖\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "\n",
    "\n",
    "# 畫原始資料趨勢圖8\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.savefig('Taipei_plot.png') \n",
    "plt.show()\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(dataset)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "days=len(testPredictPlot)\n",
    "plt.plot(scaler.inverse_transform(dataset[days-30:,:]))\n",
    "plt.plot(testPredictPlot[days-30:,:])\n",
    "plt.savefig(\"taipei_predict&real.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
